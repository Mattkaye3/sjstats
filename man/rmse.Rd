% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gof.R, R/rmse.R
\name{chisq_gof}
\alias{chisq_gof}
\alias{hoslem_gof}
\alias{rmse}
\alias{rse}
\alias{mse}
\alias{error_rate}
\alias{binned_resid}
\title{Compute model quality}
\usage{
chisq_gof(fit, prob = NULL, weights = NULL)

hoslem_gof(fit, n.bins = 10)

rmse(fit, normalized = FALSE)

rse(fit)

mse(fit)

error_rate(fit)

binned_resid(fit, term = NULL, n.bins = NULL)
}
\arguments{
\item{fit}{Fitted linear model of class \code{lm}, \code{merMod} (\pkg{lme4})
or \code{lme} (\pkg{nlme}). For \code{error_rate()} and \code{binned_resid()},
a \code{glm}-object with binomial-family. For \code{chisq_gof()}, a
numeric vector, or a \code{glm}-object.}

\item{prob}{Vector of probabilities (indicating the population probabilities)
of the same length as \code{fit}'s amount of categories / factor levels.
Use \code{nrow(table(fit))} to determine the amount of necessary values
for \code{prob}. Only used, when \code{fit} is a vector, and not a
\code{glm}-object.}

\item{weights}{Vector with weights, used to weight \code{fit}.}

\item{n.bins}{Numeric, the number of bins to divide the data. For
\code{hoslem_gof()}, the default is 10. For \code{binned_resid()}, if
\code{n.bins = NULL}, the square root of the number of observations is
taken.}

\item{normalized}{Logical, use \code{TRUE} if normalized rmse should be returned.}

\item{term}{Name of independent variable from \code{fit}. If not \code{NULL},
average residuals for the categories of \code{term} are plotted; else,
average residuals for the estimated probabilities of the response are
plotted.}
}
\value{
\describe{
  \item{\code{chisq_gof()}}{
    For vectors, returns the object of the computed \code{\link[stats]{chisq.test}}.
    \cr \cr
    For \code{glm}-objects, an object of class \code{chisq_gof} with
    following values:
    \itemize{
      \item \code{p.value} the p-value for the goodness-of-fit test
      \item \code{z.score} the standardized z-score for the goodness-of-fit test
      \item \code{RSS} the residual sums of squares term
      \item \code{X2} the pearson chi-squared statistic
    }
  }
  \item{\code{hoslem_gof()}}{
    An object of class \code{hoslem_test} with
    following values:
    \itemize{
      \item \code{chisq} the Hosmer-Lemeshow chi-squared statistic
      \item \code{df} degrees of freedom
      \item \code{p.value} the p-value for the goodness-of-fit test
    }
  }
}
}
\description{
Compute various measures or tests to assess the model quality,
  like root mean squared error, residual standard error or mean square error
  of fitted linear (mixed effects) models. For logistic regression models,
  or mixed models with binary outcome, the error rate, binned residuals,
  Chi-square goodness-of-fit-test or the Hosmer-Lemeshow Goodness-of-fit-test
  can be performed.
}
\note{
\describe{
        \item{\strong{Root Mean Square Error}}{
        The RMSE is the square root of the variance of the residuals and indicates
        the absolute fit of the model to the data (difference between observed data
        to model's predicted values). \dQuote{RMSE can be interpreted as the standard
        deviation of the unexplained variance, and has the useful property
        of being in the same units as the response variable. Lower values
        of RMSE indicate better fit. RMSE is a good measure of how accurately
        the model predicts the response, and is the most important criterion
        for fit if the main purpose of the model is prediction.}
        \cite{(Grace-Martin K: Assessing the Fit of Regression Models)}
        \cr \cr
        The normalized RMSE is the proportion of the RMSE related to the
        range of the response variable. Hence, lower values indicate
        less residual variance.
        }
        \item{\strong{Residual Standard Error}}{
        The residual standard error is the square root of the residual
        sum of squares divided by the residual degrees of freedom.
        }
        \item{\strong{Mean Square Error}}{
        The mean square error is the mean of the sum of squared residuals,
        i.e. it measures the average of the squares of the errors. Lower
        values (closer to zero) indicate better fit.
        }
        \item{\strong{Error Rate}}{
        The error rate is a crude measure for model fit for logistic regression
        models. It is defined as the proportion of cases for which the
        deterministic prediction is wrong, i.e. the proportion where the the
        predicted probability is above 0.5, although y = 0 (and vice versa).
        In general, the error rate should be below 0.5 (i.e. 50\%), the
        closer to zero, the better. Furthermore, the error rate of the full
        model should be considerably below the null model's error rate
        (cf. Gelman and Hill 2007, pp. 99).
        }
        \item{\strong{Binned Residuals}}{
        (cf. Gelman and Hill 2007, pp. 97ff).
        }
        \item{\strong{Chi-squared Goodness-of-Fit Test}}{
        For vectors, this function is a convenient function for the
        \code{chisq.test()}, performing goodness-of-fit test.
        \cr \cr
        For \code{glm}-objects, this function performs a goodness-of-fit test
        based on the \code{X2GOFtest()} function of the \CRANpkg{binomTools}
        package. A well-fitting model shows no significant difference between
        the model and the observed data, i.e. the reported p-values should be
        greater than 0.05.
        }
        \item{\strong{Hosmer-Lemeshow Goodness-of-Fit Test}}{
        A well-fitting model shows no significant difference between
        the model and the observed data, i.e. the reported p-value should be
        greater than 0.05.
        }
      }
}
\examples{
data(efc)
fit <- lm(barthtot ~ c160age + c12hour, data = efc)
rmse(fit)
rse(fit)

library(lme4)
fit <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
rmse(fit)
mse(fit)

# normalized RMSE
library(nlme)
fit <- lme(distance ~ age, data = Orthodont)
rmse(fit, normalized = TRUE)

# Error Rate
efc$neg_c_7d <- ifelse(efc$neg_c_7 < median(efc$neg_c_7, na.rm = TRUE), 0, 1)
m <- glm(
  neg_c_7d ~ c161sex + barthtot + c172code,
  data = efc,
  family = binomial(link = "logit")
)
error_rate(m)

# Binned residuals
binned_resid(m)
binned_resid(m, "barthtot")#'

# goodness-of-fit test for logistic regression
chisq_gof(m)

# goodness-of-fit test for logistic regression
hoslem_gof(m)

# goodness-of-fit test for vectors against probabilities
# differing from population
chisq_gof(efc$e42dep, c(0.3,0.2,0.22,0.28))
# equal to population
chisq_gof(efc$e42dep, prop.table(table(efc$e42dep)))#'


}
\references{
Gelman A, Hill J (2007) Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge, New York: Cambridge University Press
  \cr \cr
  Hosmer, D. W., & Lemeshow, S. (2000). Applied Logistic Regression. Hoboken, NJ, USA: John Wiley & Sons, Inc. \doi{10.1002/0471722146}
  \cr \cr
  \href{http://www.theanalysisfactor.com/assessing-the-fit-of-regression-models/}{Grace-Martin K: Assessing the Fit of Regression Models}
}
\seealso{
\code{\link{r2}} for R-squared or pseude-R-squared values, and
           \code{\link{cv}} for the coefficient of variation.
}
